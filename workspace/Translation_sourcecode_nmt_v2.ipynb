{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 20105,
     "status": "ok",
     "timestamp": 1655874395733,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "fHe5KmbTRCoI",
    "outputId": "7b24be63-3f62-4ad6-c010-3afdf718e9f1"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3249,
     "status": "ok",
     "timestamp": 1655874398975,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "W2jDPhhNldvk",
    "outputId": "4e5f7036-bacf-4273-f700-49b401d77224"
   },
   "outputs": [],
   "source": [
    "!pip install javalang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2863,
     "status": "ok",
     "timestamp": 1655874401832,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "_af0d_NseSa7"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import io\n",
    "import os\n",
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.vocab import vocab\n",
    "from torch import Tensor\n",
    "from torch.nn import (TransformerEncoder, TransformerDecoder,TransformerEncoderLayer, TransformerDecoderLayer)\n",
    "from collections import OrderedDict\n",
    "import javalang\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1655874401833,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "XwCrpAAKiPNY"
   },
   "outputs": [],
   "source": [
    "BPE_FILEPATH = \"drive/MyDrive/dissertation_workplace/code_translation/preprocessed_files/BPE\"\n",
    "OUTPUT_FILEPATH = \"drive/MyDrive/dissertation_workplace/code_translation/output_files\"\n",
    "\n",
    "SRC_LANGUAGE = \"pn\"\n",
    "TGT_LANGUAGE = \"ja\"\n",
    "MAX_COUNT = 10000\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 2e-5\n",
    "ACTIVATION = \"gelu\"\n",
    "BATCH_SIZE = 16\n",
    "NUM_ENCODER_LAYERS = 12\n",
    "NUM_ENCODER_LAYERS = 12\n",
    "TEST_MODEL = f\"{OUTPUT_FILEPATH}/sourcecode_nmt_{SRC_LANGUAGE}2{TGT_LANGUAGE}_{MAX_COUNT}C_{NUM_EPOCHS}E_{LEARNING_RATE}LR_{ACTIVATION}_{BATCH_SIZE}B_{NUM_ENCODER_LAYERS}E_{NUM_ENCODER_LAYERS}D.pth\"\n",
    "TEST_MODEL_OUTPUT_PATH = TEST_MODEL[0:-4]\n",
    "\n",
    "# Place-holders\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 553,
     "status": "ok",
     "timestamp": 1655874402382,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "oX1iP11lSME4"
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(TEST_MODEL_OUTPUT_PATH):\n",
    "  os.makedirs(TEST_MODEL_OUTPUT_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1655874402383,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "7pBBy0Lqn-d6"
   },
   "outputs": [],
   "source": [
    "def build_vocab(filename):\n",
    "  ordered_dict = OrderedDict()\n",
    "  with io.open(filename) as file:\n",
    "    for string_ in file:\n",
    "      word_feq = string_.rstrip(\"\\n\").split(\" \")\n",
    "      word = word_feq[0]\n",
    "      feq = int(word_feq[1])\n",
    "      ordered_dict[word] = feq\n",
    "  vocabulary = vocab(ordered_dict)\n",
    "  unk_token = \"<unk>\"\n",
    "  if unk_token not in vocabulary: vocabulary.insert_token(unk_token, 0)\n",
    "  vocabulary.insert_token(\"<pad>\", 1)\n",
    "  vocabulary.insert_token(\"<bos>\", 2)\n",
    "  vocabulary.insert_token(\"<eos>\", 3)\n",
    "  vocabulary.set_default_index(vocabulary[unk_token])\n",
    "  return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 1091,
     "status": "ok",
     "timestamp": 1655874403465,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "r5p7YDtrik39"
   },
   "outputs": [],
   "source": [
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "  vocab_transform[ln] = build_vocab(f\"{BPE_FILEPATH}/vocab.{ln}.{MAX_COUNT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1655874403467,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "haqwrgsRcmtD"
   },
   "outputs": [],
   "source": [
    "PAD_IDX = vocab_transform[SRC_LANGUAGE][\"<pad>\"]\n",
    "BOS_IDX = vocab_transform[SRC_LANGUAGE][\"<bos>\"]\n",
    "EOS_IDX = vocab_transform[SRC_LANGUAGE][\"<eos>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1655874403467,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "nzChtHAxIBFS"
   },
   "outputs": [],
   "source": [
    "# transformer\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_encoder_layers: int, \n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int, \n",
    "                 nhead:int,\n",
    "                 src_vocab_size: int, \n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward:int, \n",
    "                 activation:str,\n",
    "                 layer_norm_eps:float,\n",
    "                 dropout:float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        encoder_layer = TransformerEncoderLayer(d_model = emb_size, \n",
    "                                                nhead = nhead,\n",
    "                                                dim_feedforward = dim_feedforward, \n",
    "                                                activation = activation, \n",
    "                                                layer_norm_eps = layer_norm_eps)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers = num_encoder_layers)\n",
    "\n",
    "        decoder_layer = TransformerDecoderLayer(d_model = emb_size, \n",
    "                                                nhead = nhead, \n",
    "                                                dim_feedforward = dim_feedforward,\n",
    "                                                activation = activation, \n",
    "                                                layer_norm_eps = layer_norm_eps)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
    "\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, dropout = dropout)\n",
    "\n",
    "    def forward(self, src: Tensor, trg: Tensor, src_mask: Tensor,\n",
    "                tgt_mask: Tensor, src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor, memory_key_padding_mask: Tensor):\n",
    "      \n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        memory = self.transformer_encoder(src_emb, src_mask, src_padding_mask)\n",
    "        outs = self.transformer_decoder(tgt_emb, memory, tgt_mask, None, tgt_padding_mask, memory_key_padding_mask)\n",
    "\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer_encoder(self.positional_encoding(self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer_decoder(self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1655874403468,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "C98KIou7ITkd"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size: int, dropout, maxlen: int = 450):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"pos_embedding\", pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding +\n",
    "                            self.pos_embedding[:token_embedding.size(0),:])\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "        \n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1655874403469,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "6tylu3NoIYIt"
   },
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float(\"-inf\")).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 9,
     "status": "ok",
     "timestamp": 1655874403470,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "K7SpAN0hIlwb"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17521,
     "status": "ok",
     "timestamp": 1655874420983,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "f3NCAJ8Xnk_k"
   },
   "outputs": [],
   "source": [
    "transformer = torch.load(TEST_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1655874420983,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "UnKzjnSeJg4f"
   },
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        memory_mask = torch.zeros(ys.shape[0], memory.shape[0]).to(DEVICE).type(torch.bool)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0)).type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.item()\n",
    "\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "          break\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1655874420983,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "aPdml9ppKFUA"
   },
   "outputs": [],
   "source": [
    "def translate(model, src, src_vocab, tgt_vocab):\n",
    "    model.eval()\n",
    "    src_tokens = src.split(\" \")\n",
    "    tokens = [BOS_IDX] + [src_vocab.get_stoi()[tok] if tok in src_vocab.get_stoi() else 0 for tok in src_tokens] + [EOS_IDX]\n",
    "    num_tokens = len(tokens)\n",
    "    src = (torch.LongTensor(tokens).reshape(num_tokens, 1))\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(model, src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    out = \" \".join([tgt_vocab.get_itos()[tok] for tok in tgt_tokens]).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1655874420984,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "Fl7XSmHv5AYu"
   },
   "outputs": [],
   "source": [
    "def decode_bpe(x):\n",
    "  return x.replace(\"@@ \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1655874420984,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "NTguQFq0mraj"
   },
   "outputs": [],
   "source": [
    "def detokenize_java(s):\n",
    "  try:\n",
    "    tokens = javalang.tokenizer.tokenize(s)\n",
    "    return javalang.tokenizer.reformat_tokens(tokens)\n",
    "  except:\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1655874420984,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "gcsQHoVB5k1b"
   },
   "outputs": [],
   "source": [
    "def detokenize_python(s):\n",
    "    cleaned_lines = []\n",
    "    lines = s.split(\"NEWLINE\")\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"INDENT\"):\n",
    "            idn_count = line.count(\"INDENT\")\n",
    "            for i in range(idn_count):\n",
    "                if i == idn_count:\n",
    "                    line = line.replace(\"INDENT \", \"    \")\n",
    "                else:\n",
    "                    line = line.replace(\"INDENT\", \"    \")\n",
    "        line = line.replace(\"INDENT\", \"\")\n",
    "        line = line.replace(\"DEDENT \", \"\")\n",
    "        line = line.replace(\"DEDENT\", \"\")\n",
    "        line = line.replace(\"NL\", \"\")\n",
    "        line = line.replace(\"ENDMARKER\", \"\")\n",
    "        cleaned_lines.append(line)\n",
    "    code = \"\\n\".join(cleaned_lines)\n",
    "    code = code.replace(\". \", \".\").replace(\" .\", \".\")\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 7,
     "status": "ok",
     "timestamp": 1655874420985,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "YSFrjy2nnIpD"
   },
   "outputs": [],
   "source": [
    "def detokenize(s, lang):\n",
    "  if lang == \"ja\":\n",
    "    return detokenize_java(s)\n",
    "  elif lang == \"pn\":\n",
    "    return detokenize_python(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1655874421797,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "rDhxCmAeI0IJ"
   },
   "outputs": [],
   "source": [
    "def prepare_eval(s):\n",
    "    cleaned_tokens = []\n",
    "    tokens = s.split(\" \")\n",
    "    # tokens.replace(\"NEWLINE\", \"\\\\n\")\n",
    "    for token in tokens:\n",
    "      if token == \"NL\" or token == \"DEDENT\" or token == \"ENDMARKER\" or len(token) == 0 or token == \"<unk>\":\n",
    "        continue\n",
    "      elif token.startswith(\"NEWLINE\") and len(token) > len(\"NEWLINE\"):\n",
    "        token = token.replace(\"NEWLINE\", \"\")\n",
    "      elif token == \"NEWLINE\":\n",
    "        cleaned_tokens.append(\"\\\\n\")\n",
    "      elif token.startswith(\"INDENT\"):\n",
    "        idn_count = token.count(\"INDENT\")\n",
    "        for i in range(idn_count):\n",
    "          cleaned_tokens.append(\"\\\\t\")      \n",
    "      else:\n",
    "        cleaned_tokens.append(token)\n",
    "    return \" \".join(cleaned_tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1655874421797,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "VNEPXC1aU1Q2"
   },
   "outputs": [],
   "source": [
    "def cleanup(s):\n",
    "  l = re.compile(\"newline\", re.IGNORECASE).sub(\"NEWLINE\", s)\n",
    "  l = re.compile(\"new line\", re.IGNORECASE).sub(\"NEWLINE\", l)\n",
    "  l = re.compile(\"indent\", re.IGNORECASE).sub(\"INDENT\", l)\n",
    "  l = re.compile(\"dedent\", re.IGNORECASE).sub(\"DEDENT\", l)\n",
    "  return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 1169,
     "status": "ok",
     "timestamp": 1655874422963,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "JARfZc8iORxn",
    "outputId": "fb8649b7-038e-46b0-8214-46b5e1e00c0d"
   },
   "outputs": [],
   "source": [
    "# try on training data\n",
    "f = open(f\"{BPE_FILEPATH}/train.{SRC_LANGUAGE}.{MAX_COUNT}\", \"r\")\n",
    "line = f.readlines()[0]\n",
    "print(translate(transformer, line, vocab_transform[SRC_LANGUAGE], vocab_transform[TGT_LANGUAGE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1655874422964,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "D4eQX2ny35BT",
    "outputId": "0fa56742-7aa6-4b31-b6af-349659cc4d19"
   },
   "outputs": [],
   "source": [
    "# try on plain source code\n",
    "source_code = 'System . out . println ( \" Testing \" ) ' if SRC_LANGUAGE == \"ja\" else \"print('Hello World!!!')\"\n",
    "print(translate(transformer, source_code, vocab_transform[SRC_LANGUAGE], vocab_transform[TGT_LANGUAGE]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 861722,
     "status": "ok",
     "timestamp": 1655875284683,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "jL5Qrs1gEjnF"
   },
   "outputs": [],
   "source": [
    "# try on test data\n",
    "bpefile = open(f\"{BPE_FILEPATH}/test.{SRC_LANGUAGE}.{MAX_COUNT}\", \"r\")\n",
    "ref_bpefile = open(f\"{BPE_FILEPATH}/test.{TGT_LANGUAGE}.{MAX_COUNT}\", \"r\")\n",
    "bpelines = [line for line in bpefile.read().split(\"\\n\") if len(line.strip()) != 0]\n",
    "ref_bpelines = [line for line in ref_bpefile.read().split(\"\\n\") if len(line.strip()) != 0]\n",
    "\n",
    "bpe_decoded_lines = []\n",
    "cleaned_lines = []\n",
    "eval = []\n",
    "\n",
    "length = len(ref_bpelines)\n",
    "idx = 0\n",
    "\n",
    "for idx in range(length):\n",
    "  translated_line = translate(transformer, bpelines[idx], vocab_transform[SRC_LANGUAGE], vocab_transform[TGT_LANGUAGE])\n",
    "  ref_bpe_decoded = decode_bpe(ref_bpelines[idx])\n",
    "  tgt_bpe_decoded = decode_bpe(translated_line)\n",
    "  # replace <unk>\n",
    "  tgt_code = tgt_bpe_decoded.replace(\"<unk>\", \"\")\n",
    "  tgt_code = cleanup(tgt_code) if TGT_LANGUAGE == \"pn\" else tgt_code\n",
    "  cleaned_code = detokenize(tgt_code, TGT_LANGUAGE)\n",
    "  bpe_decoded_lines.append(tgt_code + \"\\n\")\n",
    "  cleaned_lines.append(cleaned_code + \"\\n\")\n",
    "\n",
    "  # prepare text for evaluation\n",
    "  if TGT_LANGUAGE == \"pn\":\n",
    "    ref = prepare_eval(ref_bpe_decoded)\n",
    "    tgt = prepare_eval(tgt_code)\n",
    "  else:\n",
    "    ref = ref_bpe_decoded\n",
    "    tgt = tgt_code\n",
    "  eval.append({\"id\": idx + 1 , \"ref\": ref, \"hyp\": tgt})\n",
    "  idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 810,
     "status": "ok",
     "timestamp": 1655875285485,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "r34NPo6nGuAc",
    "outputId": "a19e9c93-5b6d-4bf7-d416-16d7dc7caadc"
   },
   "outputs": [],
   "source": [
    "# check on test data\n",
    "print(\"BPE code in source language:\")\n",
    "print(bpelines[9])\n",
    "print(\"\\n\")\n",
    "\n",
    "translated_line = translate(transformer, bpelines[17], vocab_transform[SRC_LANGUAGE], vocab_transform[TGT_LANGUAGE])\n",
    "print(\"Translated code:\")\n",
    "print(translated_line)\n",
    "print(\"\\n\")\n",
    "\n",
    "decoded_line = decode_bpe(translated_line)\n",
    "print(\"BPE decoded code:\")\n",
    "print(decoded_line) \n",
    "print(\"\\n\")\n",
    "\n",
    "cleaned_line = detokenize(decoded_line, TGT_LANGUAGE)\n",
    "print(\"Cleaned code:\")\n",
    "print(cleaned_line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1655875285486,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "nYWTcxoPoNBn"
   },
   "outputs": [],
   "source": [
    "# store bpe decoded translated source codes in the text file\n",
    "translate_file = open(f\"{TEST_MODEL_OUTPUT_PATH}/translates.txt\", \"w\")\n",
    "translate_file.writelines(bpe_decoded_lines)\n",
    "translate_file.close()\n",
    "\n",
    "\n",
    "# store translated source codes in the text file\n",
    "count = 1\n",
    "de_translate_file = open(f\"{TEST_MODEL_OUTPUT_PATH}/detokenized_translates.txt\", \"w\")\n",
    "for i in cleaned_lines:\n",
    "  de_translate_file.writelines([f\"Solution {count}\\n\", \"---\" * 30, \"\\n\"])\n",
    "  de_translate_file.writelines(i)\n",
    "  de_translate_file.writelines([\"\\n\\n\\n\"])\n",
    "  count += 1\n",
    "de_translate_file.close()\n",
    "\n",
    "# store translates in one file\n",
    "output_file = open(f\"{TEST_MODEL_OUTPUT_PATH}/output_translates.json\", \"w\")\n",
    "json.dump({\"output\": eval}, output_file)\n",
    "output_file.close()  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1655875285486,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "eL-LaDsc90te"
   },
   "outputs": [],
   "source": [
    "if TGT_LANGUAGE == \"pn\":\n",
    "  # construct minified file and store\n",
    "  !pip install pyminifier\n",
    "  of = open(f\"{TEST_MODEL_OUTPUT_PATH}/mini_translates.txt\", \"w\")\n",
    "  count = 1\n",
    "\n",
    "  for s in cleaned_lines:\n",
    "      testfile = open(\"test.py\", \"w\")\n",
    "      testfile.writelines(detokenize(s, TGT_LANGUAGE))\n",
    "      testfile.close()\n",
    "      os.popen(\"autopep8 --in-place --aggressive --aggressive test.py\")\n",
    "      os.popen(\"pyminifier test.py > mini_testfile.py\")\n",
    "      \n",
    "      mini_testfile = open(\"mini_testfile.py\", \"r\")\n",
    "      of.writelines([f\"Solution {count}\\n\", \"---\" * 30, \"\\n\"])\n",
    "      of.writelines(mini_testfile.readlines())\n",
    "      of.writelines([\"\\n\\n\\n\"])\n",
    "      count += 1\n",
    "  of.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1655875285487,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "LmX6wAQzm1lg"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Translation_sourcecode_nmt_v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
