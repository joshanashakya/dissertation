{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Count.ipynb","provenance":[],"collapsed_sections":[],"authorship_tag":"ABX9TyMvSIv1j6EQdJt2wfVlwZq8"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU","gpuClass":"standard"},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"d6XHC6rTX1ZO","executionInfo":{"status":"ok","timestamp":1657076567856,"user_tz":-345,"elapsed":111809,"user":{"displayName":"joshana shakya","userId":"03824919138905749941"}},"outputId":"1a62feea-9428-422c-be0a-eb03c3ff02aa"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount(\"/content/drive\")"]},{"cell_type":"code","source":["import math\n","import torch\n","import torch.nn as nn\n","from torch import Tensor\n","from torch.nn import (TransformerEncoder, TransformerDecoder,TransformerEncoderLayer, TransformerDecoderLayer)"],"metadata":{"id":"zVdzP-PoYGdY","executionInfo":{"status":"ok","timestamp":1657076570324,"user_tz":-345,"elapsed":2474,"user":{"displayName":"joshana shakya","userId":"03824919138905749941"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["OUTPUT_FILEPATH = \"drive/MyDrive/dissertation_workplace/code_translation/output_files\"\n","\n","SRC_LANGUAGE = \"pn\"\n","TGT_LANGUAGE = \"ja\"\n","MAX_COUNT = 10000\n","NUM_EPOCHS = 50\n","LEARNING_RATE = 2e-5\n","ACTIVATION = \"gelu\"\n","BATCH_SIZE = 16\n","NUM_ENCODER_LAYERS = 6\n","NUM_ENCODER_LAYERS = 6\n","NHEADS = 12\n","\n","TEST_MODEL = f\"{OUTPUT_FILEPATH}/sourcecode_nmt_{SRC_LANGUAGE}2{TGT_LANGUAGE}_{MAX_COUNT}C_{NUM_EPOCHS}E_{LEARNING_RATE}LR_{ACTIVATION}_{BATCH_SIZE}B_{NUM_ENCODER_LAYERS}E_{NUM_ENCODER_LAYERS}D.pth\""],"metadata":{"id":"Chc6UDDdYPT-","executionInfo":{"status":"ok","timestamp":1657076570325,"user_tz":-345,"elapsed":7,"user":{"displayName":"joshana shakya","userId":"03824919138905749941"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["# transformer\n","class Seq2SeqTransformer(nn.Module):\n","    def __init__(self, \n","                 num_encoder_layers: int, \n","                 num_decoder_layers: int,\n","                 emb_size: int, \n","                 src_vocab_size: int, \n","                 tgt_vocab_size: int,\n","                 dim_feedforward:int, \n","                 activation:str,\n","                 layer_norm_eps:float,\n","                 dropout:float = 0.1):\n","        super(Seq2SeqTransformer, self).__init__()\n","        encoder_layer = TransformerEncoderLayer(d_model = emb_size, \n","                                                nhead = NHEAD,\n","                                                dim_feedforward = dim_feedforward, \n","                                                activation = activation, \n","                                                layer_norm_eps = layer_norm_eps)\n","        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers = num_encoder_layers)\n","\n","        decoder_layer = TransformerDecoderLayer(d_model = emb_size, \n","                                                nhead = NHEAD, \n","                                                dim_feedforward = dim_feedforward,\n","                                                activation = activation, \n","                                                layer_norm_eps = layer_norm_eps)\n","        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n","\n","        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n","        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n","        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n","        self.positional_encoding = PositionalEncoding(emb_size, dropout = dropout)\n","\n","    def forward(self, src: Tensor, trg: Tensor, src_mask: Tensor,\n","                tgt_mask: Tensor, src_padding_mask: Tensor,\n","                tgt_padding_mask: Tensor, memory_key_padding_mask: Tensor):\n","      \n","        src_emb = self.positional_encoding(self.src_tok_emb(src))\n","        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n","        memory = self.transformer_encoder(src_emb, src_mask, src_padding_mask)\n","        outs = self.transformer_decoder(tgt_emb, memory, tgt_mask, None, tgt_padding_mask, memory_key_padding_mask)\n","\n","        return self.generator(outs)\n","\n","    def encode(self, src: Tensor, src_mask: Tensor):\n","        return self.transformer_encoder(self.positional_encoding(self.src_tok_emb(src)), src_mask)\n","\n","    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n","        return self.transformer_decoder(self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask)"],"metadata":{"id":"7m2KkyNLYfVr","executionInfo":{"status":"ok","timestamp":1657076570325,"user_tz":-345,"elapsed":6,"user":{"displayName":"joshana shakya","userId":"03824919138905749941"}}},"execution_count":4,"outputs":[]},{"cell_type":"code","source":["class PositionalEncoding(nn.Module):\n","    def __init__(self, emb_size: int, dropout, maxlen: int = 450):\n","        super(PositionalEncoding, self).__init__()\n","        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n","        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n","        pos_embedding = torch.zeros((maxlen, emb_size))\n","        pos_embedding[:, 0::2] = torch.sin(pos * den)\n","        pos_embedding[:, 1::2] = torch.cos(pos * den)\n","        pos_embedding = pos_embedding.unsqueeze(-2)\n","\n","        self.dropout = nn.Dropout(dropout)\n","        self.register_buffer(\"pos_embedding\", pos_embedding)\n","\n","    def forward(self, token_embedding: Tensor):\n","        return self.dropout(token_embedding +\n","                            self.pos_embedding[:token_embedding.size(0),:])\n","\n","class TokenEmbedding(nn.Module):\n","    def __init__(self, vocab_size: int, emb_size):\n","        super(TokenEmbedding, self).__init__()\n","        self.embedding = nn.Embedding(vocab_size, emb_size)\n","        self.emb_size = emb_size\n","        \n","    def forward(self, tokens: Tensor):\n","        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"],"metadata":{"id":"LXFFdHqjYpHp","executionInfo":{"status":"ok","timestamp":1657076570325,"user_tz":-345,"elapsed":5,"user":{"displayName":"joshana shakya","userId":"03824919138905749941"}}},"execution_count":5,"outputs":[]},{"cell_type":"code","source":["model = torch.load(TEST_MODEL)"],"metadata":{"id":"ssQlx2e2YXte","executionInfo":{"status":"ok","timestamp":1657076587785,"user_tz":-345,"elapsed":17465,"user":{"displayName":"joshana shakya","userId":"03824919138905749941"}}},"execution_count":6,"outputs":[]},{"cell_type":"code","source":["pytorch_total_params = sum(p.numel() for p in model.parameters())\n","print(pytorch_total_params)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"bW-oBGUVYdr6","executionInfo":{"status":"ok","timestamp":1657076587786,"user_tz":-345,"elapsed":18,"user":{"displayName":"joshana shakya","userId":"03824919138905749941"}},"outputId":"fe190c79-7d87-48bf-fb16-07d54b3913fd"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["106944207\n"]}]},{"cell_type":"code","source":["pytorch_total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)\n","print(pytorch_total_params)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Kgnn6bczY2dM","executionInfo":{"status":"ok","timestamp":1657076587787,"user_tz":-345,"elapsed":16,"user":{"displayName":"joshana shakya","userId":"03824919138905749941"}},"outputId":"03ab2440-972f-4036-c1fe-4bc050e8d4ca"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["106944207\n"]}]},{"cell_type":"code","source":["model.parameters()"],"metadata":{"id":"UbYjeWN1Y5bh","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1657076587789,"user_tz":-345,"elapsed":14,"user":{"displayName":"joshana shakya","userId":"03824919138905749941"}},"outputId":"23b652c1-3de0-416e-ddb4-a90121a02843"},"execution_count":9,"outputs":[{"output_type":"execute_result","data":{"text/plain":["<generator object Module.parameters at 0x7f716f3236d0>"]},"metadata":{},"execution_count":9}]},{"cell_type":"code","source":[""],"metadata":{"id":"_KetffQRc8bW"},"execution_count":null,"outputs":[]}]}