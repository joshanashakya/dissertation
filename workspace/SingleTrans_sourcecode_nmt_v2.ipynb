{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 19086,
     "status": "ok",
     "timestamp": 1656907837786,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "fHe5KmbTRCoI",
    "outputId": "0ad109cc-aaa2-4b31-cf13-84e32416a456"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7515,
     "status": "ok",
     "timestamp": 1656907845298,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "W2jDPhhNldvk",
    "outputId": "60c2894f-75be-46dc-c113-ba94bc126c6a"
   },
   "outputs": [],
   "source": [
    "!pip install javalang\n",
    "!pip install pyminifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 4105,
     "status": "ok",
     "timestamp": 1656907849397,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "5tEi7EBbZa5J",
    "outputId": "3ea2a3b4-6fd3-42c5-b6c3-8083769ce695"
   },
   "outputs": [],
   "source": [
    "# install fastBPE\n",
    "!git clone https://github.com/glample/fastBPE.git\n",
    "%cd fastBPE\n",
    "!g++ -std=c++11 -pthread -O3 fastBPE/main.cc -IfastBPE -o fast\n",
    "%cd .."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2781,
     "status": "ok",
     "timestamp": 1656907852174,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "_af0d_NseSa7"
   },
   "outputs": [],
   "source": [
    "import math\n",
    "import io\n",
    "import os\n",
    "import torchtext\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchtext.vocab import vocab\n",
    "from torch import Tensor\n",
    "from torch.nn import (TransformerEncoder, TransformerDecoder,TransformerEncoderLayer, TransformerDecoderLayer)\n",
    "from collections import OrderedDict\n",
    "import javalang\n",
    "import tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1656907852174,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "XwCrpAAKiPNY"
   },
   "outputs": [],
   "source": [
    "BPE_FILEPATH = \"drive/MyDrive/dissertation_workplace/code_translation/preprocessed_files/BPE\"\n",
    "OUTPUT_FILEPATH = \"drive/MyDrive/dissertation_workplace/code_translation/output_files\"\n",
    "\n",
    "SRC_LANGUAGE = \"pn\"\n",
    "TGT_LANGUAGE = \"ja\"\n",
    "MAX_COUNT = 10000\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 2e-5\n",
    "ACTIVATION = \"gelu\"\n",
    "BATCH_SIZE = 16\n",
    "NUM_ENCODER_LAYERS = 6\n",
    "NUM_ENCODER_LAYERS = 6\n",
    "SRC_FILE = \"2_650.py\"\n",
    "\n",
    "SRC_TOK_FILE = f\"test_tok.{SRC_LANGUAGE}\"\n",
    "SRC_BPE_FILE = f\"test.{SRC_LANGUAGE}\"\n",
    "\n",
    "TEST_MODEL = f\"{OUTPUT_FILEPATH}/sourcecode_nmt_{SRC_LANGUAGE}2{TGT_LANGUAGE}_{MAX_COUNT}C_{NUM_EPOCHS}E_{LEARNING_RATE}LR_{ACTIVATION}_{BATCH_SIZE}B_{NUM_ENCODER_LAYERS}E_{NUM_ENCODER_LAYERS}D.pth\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1656907852175,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "qcVeO5Fx24lD"
   },
   "outputs": [],
   "source": [
    "def minify(file):\n",
    "   mini_filepath = \"mini_\" + file\n",
    "   os.popen(f\"pyminifier {file} > {mini_filepath}\")\n",
    "   return mini_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1656907852175,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "d2BxlXlAal3E"
   },
   "outputs": [],
   "source": [
    "def tokenize_java(filepath):\n",
    "    file = open(filepath, \"r\", encoding = \"ISO-8859-1\")\n",
    "    tokens = javalang.tokenizer.tokenize(file.read())\n",
    "    code = []\n",
    "    for token in tokens:\n",
    "        code.append(token.value)\n",
    "#     print(f\"Java Tokens Count: {len(code)}\")\n",
    "    return \" \".join(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1656907852176,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "6rpAoJaBa7i6"
   },
   "outputs": [],
   "source": [
    "def tokenize_python(filepath):\n",
    "    code = []\n",
    "    with tokenize.open(filepath) as f:\n",
    "        tokens = tokenize.generate_tokens(f.readline)\n",
    "        pre_token = None\n",
    "        for token in tokens:\n",
    "            if (pre_token != None and pre_token.type == tokenize.COMMENT and token.type == tokenize.NL) or (token.type == tokenize.COMMENT):\n",
    "                pre_token = token\n",
    "                continue\n",
    "            elif token.type == tokenize.NEWLINE:\n",
    "                val = token.string.replace(\"\\n\", \"NEWLINE\")\n",
    "            elif token.type == tokenize.NL:\n",
    "                val = \"NL\"\n",
    "            elif token.type == tokenize.INDENT and token.string.isspace():\n",
    "                no = int(len(token.string))\n",
    "                val = \"INDENT\" * no\n",
    "            elif token.type == tokenize.INDENT:\n",
    "                val = token.string.replace(\"\\t\", \"INDENT\")\n",
    "            elif token.type == tokenize.DEDENT:\n",
    "                val = \"DEDENT\"\n",
    "            elif token.type == tokenize.ENDMARKER:\n",
    "                val = \"ENDMARKER\"\n",
    "            else:\n",
    "                val = token.string\n",
    "            pre_token = token\n",
    "            code.append(val)\n",
    "#     print(f\"Python Tokens Count: {len(code)}\")\n",
    "    return \" \".join(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1656907852177,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "idA1dIIqbH4i"
   },
   "outputs": [],
   "source": [
    "def tokenize_code(filepath, lang):\n",
    "  if lang == \"ja\":\n",
    "    return tokenize_java(filepath)\n",
    "  else:\n",
    "    mini_filepath = minify(filepath)\n",
    "    return tokenize_python(mini_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 684,
     "status": "ok",
     "timestamp": 1656907856741,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "VIsnCRa0bd37",
    "outputId": "c4c9626b-659b-47ac-e2c3-4d27d09cff07"
   },
   "outputs": [],
   "source": [
    "# pre-tokenization of source language code\n",
    "src = tokenize_code(SRC_FILE, SRC_LANGUAGE)\n",
    "print(src)\n",
    "with open(SRC_TOK_FILE, \"w\") as f:\n",
    "  f.write(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 563,
     "status": "ok",
     "timestamp": 1656907857884,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "nI3pQGcKbywU",
    "outputId": "e290c001-567e-4255-be45-10a00ac09f7b"
   },
   "outputs": [],
   "source": [
    "# BPE tokenization of source language code\n",
    "SRC_VOCAB_FILE = f\"{BPE_FILEPATH}/vocab.{SRC_LANGUAGE}.{MAX_COUNT}\"\n",
    "!./fastBPE/fast applybpe $SRC_BPE_FILE $SRC_TOK_FILE $BPE_FILEPATH/codes $SRC_VOCAB_FILE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1656907857885,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "NtGQvKTsZmvl"
   },
   "outputs": [],
   "source": [
    "# Place-holders\n",
    "vocab_transform = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1656907857885,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "7pBBy0Lqn-d6"
   },
   "outputs": [],
   "source": [
    "def build_vocab(filename):\n",
    "  ordered_dict = OrderedDict()\n",
    "  with io.open(filename) as file:\n",
    "    for string_ in file:\n",
    "      word_feq = string_.rstrip(\"\\n\").split(\" \")\n",
    "      word = word_feq[0]\n",
    "      feq = int(word_feq[1])\n",
    "      ordered_dict[word] = feq\n",
    "  vocabulary = vocab(ordered_dict)\n",
    "  unk_token = \"<unk>\"\n",
    "  if unk_token not in vocabulary: vocabulary.insert_token(unk_token, 0)\n",
    "  vocabulary.insert_token(\"<pad>\", 1)\n",
    "  vocabulary.insert_token(\"<bos>\", 2)\n",
    "  vocabulary.insert_token(\"<eos>\", 3)\n",
    "  vocabulary.set_default_index(vocabulary[unk_token])\n",
    "  return vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 364,
     "status": "ok",
     "timestamp": 1656907858247,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "r5p7YDtrik39"
   },
   "outputs": [],
   "source": [
    "for ln in [SRC_LANGUAGE, TGT_LANGUAGE]:\n",
    "  vocab_transform[ln] = build_vocab(f\"{BPE_FILEPATH}/vocab.{ln}.{MAX_COUNT}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1656907858247,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "haqwrgsRcmtD"
   },
   "outputs": [],
   "source": [
    "PAD_IDX = vocab_transform[SRC_LANGUAGE][\"<pad>\"]\n",
    "BOS_IDX = vocab_transform[SRC_LANGUAGE][\"<bos>\"]\n",
    "EOS_IDX = vocab_transform[SRC_LANGUAGE][\"<eos>\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1656907858644,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "nzChtHAxIBFS"
   },
   "outputs": [],
   "source": [
    "# transformer\n",
    "class Seq2SeqTransformer(nn.Module):\n",
    "    def __init__(self, \n",
    "                 num_encoder_layers: int, \n",
    "                 num_decoder_layers: int,\n",
    "                 emb_size: int, \n",
    "                 src_vocab_size: int, \n",
    "                 tgt_vocab_size: int,\n",
    "                 dim_feedforward:int, \n",
    "                 activation:str,\n",
    "                 layer_norm_eps:float,\n",
    "                 dropout:float = 0.1):\n",
    "        super(Seq2SeqTransformer, self).__init__()\n",
    "        encoder_layer = TransformerEncoderLayer(d_model = emb_size, \n",
    "                                                nhead = NHEAD,\n",
    "                                                dim_feedforward = dim_feedforward, \n",
    "                                                activation = activation, \n",
    "                                                layer_norm_eps = layer_norm_eps)\n",
    "        self.transformer_encoder = TransformerEncoder(encoder_layer, num_layers = num_encoder_layers)\n",
    "\n",
    "        decoder_layer = TransformerDecoderLayer(d_model = emb_size, \n",
    "                                                nhead = NHEAD, \n",
    "                                                dim_feedforward = dim_feedforward,\n",
    "                                                activation = activation, \n",
    "                                                layer_norm_eps = layer_norm_eps)\n",
    "        self.transformer_decoder = TransformerDecoder(decoder_layer, num_layers=num_decoder_layers)\n",
    "\n",
    "        self.generator = nn.Linear(emb_size, tgt_vocab_size)\n",
    "        self.src_tok_emb = TokenEmbedding(src_vocab_size, emb_size)\n",
    "        self.tgt_tok_emb = TokenEmbedding(tgt_vocab_size, emb_size)\n",
    "        self.positional_encoding = PositionalEncoding(emb_size, dropout = dropout)\n",
    "\n",
    "    def forward(self, src: Tensor, trg: Tensor, src_mask: Tensor,\n",
    "                tgt_mask: Tensor, src_padding_mask: Tensor,\n",
    "                tgt_padding_mask: Tensor, memory_key_padding_mask: Tensor):\n",
    "      \n",
    "        src_emb = self.positional_encoding(self.src_tok_emb(src))\n",
    "        tgt_emb = self.positional_encoding(self.tgt_tok_emb(trg))\n",
    "        memory = self.transformer_encoder(src_emb, src_mask, src_padding_mask)\n",
    "        outs = self.transformer_decoder(tgt_emb, memory, tgt_mask, None, tgt_padding_mask, memory_key_padding_mask)\n",
    "\n",
    "        return self.generator(outs)\n",
    "\n",
    "    def encode(self, src: Tensor, src_mask: Tensor):\n",
    "        return self.transformer_encoder(self.positional_encoding(self.src_tok_emb(src)), src_mask)\n",
    "\n",
    "    def decode(self, tgt: Tensor, memory: Tensor, tgt_mask: Tensor):\n",
    "        return self.transformer_decoder(self.positional_encoding(self.tgt_tok_emb(tgt)), memory, tgt_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1656907860422,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "C98KIou7ITkd"
   },
   "outputs": [],
   "source": [
    "class PositionalEncoding(nn.Module):\n",
    "    def __init__(self, emb_size: int, dropout, maxlen: int = 450):\n",
    "        super(PositionalEncoding, self).__init__()\n",
    "        den = torch.exp(- torch.arange(0, emb_size, 2) * math.log(10000) / emb_size)\n",
    "        pos = torch.arange(0, maxlen).reshape(maxlen, 1)\n",
    "        pos_embedding = torch.zeros((maxlen, emb_size))\n",
    "        pos_embedding[:, 0::2] = torch.sin(pos * den)\n",
    "        pos_embedding[:, 1::2] = torch.cos(pos * den)\n",
    "        pos_embedding = pos_embedding.unsqueeze(-2)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.register_buffer(\"pos_embedding\", pos_embedding)\n",
    "\n",
    "    def forward(self, token_embedding: Tensor):\n",
    "        return self.dropout(token_embedding +\n",
    "                            self.pos_embedding[:token_embedding.size(0),:])\n",
    "\n",
    "class TokenEmbedding(nn.Module):\n",
    "    def __init__(self, vocab_size: int, emb_size):\n",
    "        super(TokenEmbedding, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, emb_size)\n",
    "        self.emb_size = emb_size\n",
    "        \n",
    "    def forward(self, tokens: Tensor):\n",
    "        return self.embedding(tokens.long()) * math.sqrt(self.emb_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1656907860422,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "6tylu3NoIYIt"
   },
   "outputs": [],
   "source": [
    "def generate_square_subsequent_mask(sz):\n",
    "    mask = (torch.triu(torch.ones((sz, sz), device=DEVICE)) == 1).transpose(0, 1)\n",
    "    mask = mask.float().masked_fill(mask == 0, float(\"-inf\")).masked_fill(mask == 1, float(0.0))\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 2,
     "status": "ok",
     "timestamp": 1656907860755,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "K7SpAN0hIlwb"
   },
   "outputs": [],
   "source": [
    "DEVICE = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14093,
     "status": "ok",
     "timestamp": 1656907874847,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "f3NCAJ8Xnk_k"
   },
   "outputs": [],
   "source": [
    "transformer = torch.load(TEST_MODEL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 17,
     "status": "ok",
     "timestamp": 1656907874848,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "UnKzjnSeJg4f"
   },
   "outputs": [],
   "source": [
    "def greedy_decode(model, src, src_mask, max_len, start_symbol):\n",
    "    src = src.to(DEVICE)\n",
    "    src_mask = src_mask.to(DEVICE)\n",
    "    memory = model.encode(src, src_mask)\n",
    "    ys = torch.ones(1, 1).fill_(start_symbol).type(torch.long).to(DEVICE)\n",
    "    for i in range(max_len-1):\n",
    "        memory = memory.to(DEVICE)\n",
    "        memory_mask = torch.zeros(ys.shape[0], memory.shape[0]).to(DEVICE).type(torch.bool)\n",
    "        tgt_mask = (generate_square_subsequent_mask(ys.size(0)).type(torch.bool)).to(DEVICE)\n",
    "        out = model.decode(ys, memory, tgt_mask)\n",
    "        out = out.transpose(0, 1)\n",
    "        prob = model.generator(out[:, -1])\n",
    "        _, next_word = torch.max(prob, dim = 1)\n",
    "        next_word = next_word.item()\n",
    "        ys = torch.cat([ys, torch.ones(1, 1).type_as(src.data).fill_(next_word)], dim=0)\n",
    "        if next_word == EOS_IDX:\n",
    "          break\n",
    "    return ys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1656907874850,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "aPdml9ppKFUA"
   },
   "outputs": [],
   "source": [
    "def translate(model, src, src_vocab, tgt_vocab):\n",
    "    model.eval()\n",
    "    src_tokens = src.split(\" \")\n",
    "    tokens = [BOS_IDX] + [src_vocab.get_stoi()[tok] if tok in src_vocab.get_stoi() else 0 for tok in src_tokens] + [EOS_IDX]\n",
    "    num_tokens = len(tokens)\n",
    "    src = (torch.LongTensor(tokens).reshape(num_tokens, 1))\n",
    "    src_mask = (torch.zeros(num_tokens, num_tokens)).type(torch.bool)\n",
    "    tgt_tokens = greedy_decode(model, src, src_mask, max_len=num_tokens + 5, start_symbol=BOS_IDX).flatten()\n",
    "    out = \" \".join([tgt_vocab.get_itos()[tok] for tok in tgt_tokens]).replace(\"<bos>\", \"\").replace(\"<eos>\", \"\")\n",
    "    return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 14,
     "status": "ok",
     "timestamp": 1656907874850,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "Fl7XSmHv5AYu"
   },
   "outputs": [],
   "source": [
    "def decode_bpe(x):\n",
    "  return x.replace(\"@@ \", \"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1656907874851,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "NTguQFq0mraj"
   },
   "outputs": [],
   "source": [
    "def detokenize_java(s):\n",
    "  try:\n",
    "    tokens = javalang.tokenizer.tokenize(s)\n",
    "    return javalang.tokenizer.reformat_tokens(tokens)\n",
    "  except:\n",
    "    return s\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1656907874851,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "gcsQHoVB5k1b"
   },
   "outputs": [],
   "source": [
    "def detokenize_python(s):\n",
    "    cleaned_lines = []\n",
    "    lines = s.split(\"NEWLINE\")\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"INDENT\"):\n",
    "            idn_count = line.count(\"INDENT\")\n",
    "            for i in range(idn_count):\n",
    "                if i == idn_count:\n",
    "                    line = line.replace(\"INDENT \", \"    \")\n",
    "                else:\n",
    "                    line = line.replace(\"INDENT\", \"    \")\n",
    "        line = line.replace(\"INDENT\", \"\")\n",
    "        line = line.replace(\"DEDENT \", \"\")\n",
    "        line = line.replace(\"DEDENT\", \"\")\n",
    "        line = line.replace(\"NL\", \"\")\n",
    "        line = line.replace(\"ENDMARKER\", \"\")\n",
    "        cleaned_lines.append(line)\n",
    "    code = \"\\n\".join(cleaned_lines)\n",
    "    code = code.replace(\". \", \".\").replace(\" .\", \".\")\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 13,
     "status": "ok",
     "timestamp": 1656907874852,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "YSFrjy2nnIpD"
   },
   "outputs": [],
   "source": [
    "def detokenize_code(s, lang):\n",
    "  if lang == \"ja\":\n",
    "    return detokenize_java(s)\n",
    "  elif lang == \"pn\":\n",
    "    return detokenize_python(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1656907874852,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "uxv_1OnBXG4I"
   },
   "outputs": [],
   "source": [
    "def cleanup(s):\n",
    "  l = re.compile(\"newline\", re.IGNORECASE).sub(\"NEWLINE\", s)\n",
    "  l = re.compile(\"new line\", re.IGNORECASE).sub(\"NEWLINE\", l)\n",
    "  l = re.compile(\"indent\", re.IGNORECASE).sub(\"INDENT\", l)\n",
    "  l = re.compile(\"dedent\", re.IGNORECASE).sub(\"DEDENT\", l)\n",
    "  return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 2133,
     "status": "ok",
     "timestamp": 1656907876973,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "JARfZc8iORxn",
    "outputId": "f623053f-4ee6-4d03-d7a8-9eb436042942"
   },
   "outputs": [],
   "source": [
    "SRC_LANG = \"Java\" if SRC_LANGUAGE == \"ja\" else \"Python\"\n",
    "TGT_LANG = \"Java\" if TGT_LANGUAGE == \"ja\" else \"Python\"\n",
    "\n",
    "# try on single file\n",
    "with open(SRC_FILE, \"r\") as f:\n",
    "  src_code = f.read()\n",
    "print(f\"Program in \\\"{SRC_LANG}\\\":\")\n",
    "print(src_code)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "with open(SRC_BPE_FILE, \"r\") as f:\n",
    "  bpe_code = f.read()\n",
    "print(f\"BPE of program in \\\"{SRC_LANG}\\\":\")\n",
    "print(bpe_code)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "translated_bpe = translate(transformer, bpe_code, vocab_transform[SRC_LANGUAGE], vocab_transform[TGT_LANGUAGE])\n",
    "print(f\"Translated BPE of program in the target language \\\"{TGT_LANG}\\\":\")\n",
    "print(translated_bpe)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "decoded_code = decode_bpe(translated_bpe)\n",
    "print(f\"BPE decoded program in the target language \\\"{TGT_LANG}\\\":\")\n",
    "print(decoded_code)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "detokenized_code = detokenize_code(cleanup(decoded_code), TGT_LANGUAGE);\n",
    "print(f\"Detokenized program in the target language \\\"{TGT_LANG}\\\":\")\n",
    "print(detokenized_code)\n",
    "\n",
    "TGT_EXT = \"java\" if TGT_LANGUAGE == \"ja\" else \"py\"\n",
    "TGT_FILE = f\"translate.{TGT_EXT}\"\n",
    "with open(TGT_FILE, \"w\") as f:\n",
    "  f.write(detokenized_code)\n",
    "\n",
    "if TGT_LANGUAGE == \"pn\":\n",
    "  # construct minified file and store\n",
    "  !pip install pyminifier\n",
    "  os.popen(\"autopep8 --in-place --aggressive --aggressive translate.py\")\n",
    "  os.popen(\"pyminifier translate.py > mini_translate.py\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1656907876973,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "LmX6wAQzm1lg"
   },
   "outputs": [],
   "source": [
    "# write everything to a file\n",
    "txt =\"\"\n",
    "txt1 = f\"Program in \\\"{SRC_LANG}\\\":\\n\"\n",
    "txt += f\"{txt1}{'=' * len(txt1)}\\n{src_code}\\n\\n\"\n",
    "txt2 = f\"BPE of program in \\\"{SRC_LANG}\\\":\\n\"\n",
    "txt += f\"{txt2}{'=' * len(txt2)}\\n{bpe_code}\\n\\n\\n\"\n",
    "txt3 = f\"Translated BPE of program in the target language \\\"{TGT_LANG}\\\":\\n\"\n",
    "txt += f\"{txt3}{'=' * len(txt3)}\\n{translated_bpe}\\n\\n\\n\"\n",
    "txt4 = f\"BPE decoded program in the target language \\\"{TGT_LANG}\\\":\\n\"\n",
    "txt += f\"{txt4}{'=' * len(txt4)}\\n{decoded_code}\\n\\n\\n\"\n",
    "txt5 = f\"Detokenized program in the target language \\\"{TGT_LANG}\\\":\\n\"\n",
    "txt += f\"{txt5}{'=' * len(txt5)}\\n{detokenized_code}\\n\\n\\n\"\n",
    "\n",
    "if TGT_LANGUAGE == \"pn\":\n",
    "  txt6 = f\"Minified program:\\n\"\n",
    "  with open(\"mini_translate.py\", \"r\") as f:\n",
    "    mini = f.read()\n",
    "  txt += f\"{txt6}{'=' * len(txt6)}\\n{mini}\\n\\n\\n\"\n",
    "\n",
    "with open(\"details.txt\", \"w\") as f:\n",
    "  f.write(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1656907876974,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "qNPa9Ie8Gtxr"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "SingleTrans_sourcecode_nmt_v2.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
