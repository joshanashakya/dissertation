{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 18368,
     "status": "ok",
     "timestamp": 1656230038509,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "RFIkiWiVZ510",
    "outputId": "1b6f7777-0f23-4dd8-9dd0-cb0439cc4b85"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount(\"/content/drive\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 24522,
     "status": "ok",
     "timestamp": 1656230063024,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "m1CEgeR8otQD"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install datasets\n",
    "!pip install transformers\n",
    "!pip install javalang\n",
    "!pip install pyminifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 3556,
     "status": "ok",
     "timestamp": 1656230066572,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "7A-gW3PkYvJY"
   },
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer, EncoderDecoderModel\n",
    "import torch\n",
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import os\n",
    "import javalang\n",
    "import tokenize\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1656230066573,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "IpvPG2-NQfVX"
   },
   "outputs": [],
   "source": [
    "BPE_FILEPATH = \"drive/MyDrive/dissertation_workplace/code_translation/preprocessed_files/BPE\"\n",
    "OUTPUT_FILEPATH = \"drive/MyDrive/dissertation_workplace/code_translation/output_files\"\n",
    "\n",
    "SRC_LANGUAGE = \"pn\"\n",
    "TGT_LANGUAGE = \"ja\"\n",
    "NUM_EPOCHS = 100\n",
    "LEARNING_RATE = 2e-5\n",
    "NUM_LAYERS = 6\n",
    "BATCH_SIZE = 16\n",
    "SRC_FILE = \"2.py\"\n",
    "\n",
    "SRC_TOK_FILE = f\"test_tok.{SRC_LANGUAGE}\"\n",
    "SRC_CB_FILE = f\"test.{SRC_LANGUAGE}\"\n",
    "\n",
    "TEST_MODEL = f\"codebert_sourcecode_nmt_{SRC_LANGUAGE}2{TGT_LANGUAGE}_{NUM_EPOCHS}E_{LEARNING_RATE}LR_{BATCH_SIZE}B_{NUM_LAYERS}E_{NUM_LAYERS}D\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 12,
     "status": "ok",
     "timestamp": 1656230066574,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "q3w1DCsRPwO3"
   },
   "outputs": [],
   "source": [
    "def minify(file):\n",
    "   mini_filepath = \"mini_\" + file\n",
    "   os.popen(f\"pyminifier {file} > {mini_filepath}\")\n",
    "   return mini_filepath"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 11,
     "status": "ok",
     "timestamp": 1656230066574,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "grBlKMPDQJs-"
   },
   "outputs": [],
   "source": [
    "def tokenize_java(filepath):\n",
    "    file = open(filepath, \"r\", encoding = \"ISO-8859-1\")\n",
    "    tokens = javalang.tokenizer.tokenize(file.read())\n",
    "    code = []\n",
    "    for token in tokens:\n",
    "        code.append(token.value)\n",
    "#     print(f\"Java Tokens Count: {len(code)}\")\n",
    "    return \" \".join(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 10,
     "status": "ok",
     "timestamp": 1656230066574,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "Dtq20xA0QLBf"
   },
   "outputs": [],
   "source": [
    "def detokenize_java(s):\n",
    "    try:\n",
    "        tokens = javalang.tokenizer.tokenize(s)\n",
    "        return javalang.tokenizer.reformat_tokens(tokens)\n",
    "    except:\n",
    "        return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 812,
     "status": "ok",
     "timestamp": 1656230067376,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "5jSklC8iQOkV"
   },
   "outputs": [],
   "source": [
    "def tokenize_python(filepath):\n",
    "    code = \"\"\n",
    "    with tokenize.open(filepath) as f:\n",
    "        tokens = tokenize.generate_tokens(f.readline)\n",
    "        pre_token = None\n",
    "        for token in tokens:\n",
    "            if (pre_token != None and pre_token.type == tokenize.COMMENT and token.type == tokenize.NL) or (token.type == tokenize.COMMENT):\n",
    "                pre_token = token\n",
    "                continue\n",
    "            elif token.type == tokenize.NEWLINE:\n",
    "                temp = token.string.replace(\"\\n\", \"NEWLINE\")\n",
    "                val = \" \" + temp\n",
    "            elif token.type == tokenize.NL:\n",
    "                temp = \"NL\"\n",
    "                val = \" \" + temp\n",
    "            elif token.type == tokenize.INDENT and token.string.isspace():\n",
    "                no = int(len(token.string))\n",
    "                temp = \"INDENT\" * no\n",
    "                val = \" \" + temp\n",
    "            elif token.type == tokenize.INDENT:\n",
    "                temp = token.string.replace(\"\\t\", \"INDENT\")\n",
    "                val = \" \" + temp\n",
    "            elif token.type == tokenize.DEDENT:\n",
    "                temp = \"DEDENT\"\n",
    "                val = \" \" + temp + \" \"\n",
    "            elif token.type == tokenize.ENDMARKER:\n",
    "                temp = \"ENDMARKER\"\n",
    "                val = \" \" + temp\n",
    "            else:\n",
    "                start = token.start\n",
    "                line = token.line\n",
    "                space_idx = start[1] - 1\n",
    "                if line[space_idx] == \" \" or (pre_token != None and pre_token.type == tokenize.NEWLINE):\n",
    "                    val = \" \" + token.string\n",
    "                else:\n",
    "                    val = token.string\n",
    "                \n",
    "            pre_token = token\n",
    "            code += val\n",
    "#     print(f\"Length of Python code: {len(code)}\")\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 18,
     "status": "ok",
     "timestamp": 1656230067377,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "TLUgExgIQXo_"
   },
   "outputs": [],
   "source": [
    "def tokenize_code(filepath, lang):\n",
    "  if lang == \"ja\":\n",
    "    return \" \".join(detokenize_java(tokenize_java(filepath)).split())\n",
    "  else:\n",
    "    mini_filepath = minify(filepath)\n",
    "    return tokenize_python(mini_filepath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 3,
     "status": "ok",
     "timestamp": 1656230077223,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "bRd9DU_0Qk-E",
    "outputId": "7ff5ccbe-7bfa-4541-9424-57dd3bdfc8a0"
   },
   "outputs": [],
   "source": [
    "# pre-tokenization of source language code\n",
    "src = tokenize_code(SRC_FILE, SRC_LANGUAGE)\n",
    "print(src)\n",
    "with open(SRC_TOK_FILE, \"w\") as f:\n",
    "  f.write(src)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1656230077580,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "OPkWGsLF0Ox3"
   },
   "outputs": [],
   "source": [
    "def save_codebert_tokens(input_ids, tokenizer):\n",
    "  with open(SRC_CB_FILE, \"w\") as f:\n",
    "    f.write(\" \".join(tokenizer.convert_ids_to_tokens(input_ids[0].tolist(), skip_special_tokens = True)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "executionInfo": {
     "elapsed": 32972,
     "status": "ok",
     "timestamp": 1656230110549,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "FySAFdlhY0X0",
    "outputId": "f9e5f683-69f8-4ab3-bb0f-8f00185e8a28"
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "tokenizer = RobertaTokenizer.from_pretrained(\"microsoft/codebert-base\")\n",
    "model = EncoderDecoderModel.from_pretrained(f\"joshanashakya/{TEST_MODEL}\")\n",
    "model.to(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 19,
     "status": "ok",
     "timestamp": 1656230110550,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "AchEtis3gtlU"
   },
   "outputs": [],
   "source": [
    "def translate(src):\n",
    "  inputs = tokenizer(src, padding=\"max_length\", truncation=True, max_length=450, return_tensors=\"pt\")\n",
    "  input_ids = inputs.input_ids.to(\"cuda\")\n",
    "  save_codebert_tokens(input_ids, tokenizer)\n",
    "  attention_mask = inputs.attention_mask.to(\"cuda\")\n",
    "\n",
    "  outputs = model.generate(input_ids, attention_mask=attention_mask)\n",
    "\n",
    "  # all special tokens including will be removed\n",
    "  output_str = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "  return output_str[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 16,
     "status": "ok",
     "timestamp": 1656230110551,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "3YM6nvaqfJ8D"
   },
   "outputs": [],
   "source": [
    "def detokenize_java(s):\n",
    "  try:\n",
    "    tokens = javalang.tokenizer.tokenize(s)\n",
    "    return javalang.tokenizer.reformat_tokens(tokens)\n",
    "  except:\n",
    "    return s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1656230110552,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "gpU4GNqwkiS6"
   },
   "outputs": [],
   "source": [
    "def detokenize_python(s):\n",
    "    cleaned_lines = []\n",
    "    lines = s.split(\"NEWLINE\")\n",
    "    for line in lines:\n",
    "        line = line.strip()\n",
    "        if line.startswith(\"INDENT\"):\n",
    "            idn_count = line.count(\"INDENT\")\n",
    "            for i in range(idn_count):\n",
    "                if i == idn_count:\n",
    "                    line = line.replace(\"INDENT \", \"    \")\n",
    "                else:\n",
    "                    line = line.replace(\"INDENT\", \"    \")\n",
    "        line = line.replace(\"INDENT\", \"\")\n",
    "        line = line.replace(\"DEDENT \", \"\")\n",
    "        line = line.replace(\"DEDENT\", \"\")\n",
    "        line = line.replace(\"NL\", \"\")\n",
    "        line = line.replace(\"ENDMARKER\", \"\")\n",
    "        cleaned_lines.append(line)\n",
    "    code = \"\\n\".join(cleaned_lines)\n",
    "    code = code.replace(\". \", \".\").replace(\" .\", \".\")\n",
    "    return code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1656230110553,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "Y37mlioFkojs"
   },
   "outputs": [],
   "source": [
    "def detokenize(s, lang):\n",
    "  if lang == \"ja\":\n",
    "    return detokenize_java(s)\n",
    "  elif lang == \"pn\":\n",
    "    return detokenize_python(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "ok",
     "timestamp": 1656230110553,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "xxZoMsspXlsV"
   },
   "outputs": [],
   "source": [
    "def cleanup(s):\n",
    "  l = re.compile(\"newline\", re.IGNORECASE).sub(\"NEWLINE\", s)\n",
    "  l = re.compile(\"new line\", re.IGNORECASE).sub(\"NEWLINE\", l)\n",
    "  l = re.compile(\"indent\", re.IGNORECASE).sub(\"INDENT\", l)\n",
    "  l = re.compile(\"dedent\", re.IGNORECASE).sub(\"DEDENT\", l)\n",
    "  return l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5851,
     "status": "ok",
     "timestamp": 1656230116392,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "lHB0aFeOTbTq",
    "outputId": "41d2c8a3-febe-4d65-de87-22e139e5f215"
   },
   "outputs": [],
   "source": [
    "SRC_LANG = \"Java\" if SRC_LANGUAGE == \"ja\" else \"Python\"\n",
    "TGT_LANG = \"Java\" if TGT_LANGUAGE == \"ja\" else \"Python\"\n",
    "\n",
    "# try on single file\n",
    "with open(SRC_FILE, \"r\") as f:\n",
    "  src_code = f.read()\n",
    "print(f\"Program in \\\"{SRC_LANG}\\\":\")\n",
    "print(src_code)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "translated_code = translate(src)\n",
    "print(f\"Translated program in the target language \\\"{TGT_LANG}\\\":\")\n",
    "print(translated_code)\n",
    "print(\"\\n\\n\")\n",
    "\n",
    "detokenized_code = detokenize(cleanup(translated_code), TGT_LANGUAGE)\n",
    "print(f\"Detokenized program in the target language \\\"{TGT_LANG}\\\":\")\n",
    "print(detokenized_code)\n",
    "\n",
    "TGT_EXT = \"java\" if TGT_LANGUAGE == \"ja\" else \"py\"\n",
    "TGT_FILE = f\"translate.{TGT_EXT}\"\n",
    "with open(TGT_FILE, \"w\") as f:\n",
    "  f.write(detokenized_code)\n",
    "\n",
    "if TGT_LANGUAGE == \"pn\":\n",
    "  # construct minified file and store\n",
    "  !pip install pyminifier\n",
    "  os.popen(\"autopep8 --in-place --aggressive --aggressive translate.py\")\n",
    "  os.popen(\"pyminifier translate.py > mini_translate.py\")\n",
    "      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 8,
     "status": "ok",
     "timestamp": 1656230116393,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "CotV5XW6nnX6"
   },
   "outputs": [],
   "source": [
    "# write everything to a file\n",
    "txt =\"\"\n",
    "txt1 = f\"Program in \\\"{SRC_LANG}\\\":\\n\"\n",
    "txt += f\"{txt1}{'=' * len(txt1)}\\n{src_code}\\n\\n\"\n",
    "txt2 = f\"Translated program in the target language \\\"{TGT_LANG}\\\":\\n\"\n",
    "txt += f\"{txt2}{'=' * len(txt2)}\\n{translated_code}\\n\\n\\n\"\n",
    "txt3 = f\"Detokenized program in the target language \\\"{TGT_LANG}\\\":\\n\"\n",
    "txt += f\"{txt3}{'=' * len(txt3)}\\n{detokenized_code}\\n\\n\\n\"\n",
    "\n",
    "if TGT_LANGUAGE == \"pn\":\n",
    "  txt6 = f\"Minified program:\\n\"\n",
    "  with open(\"mini_translate.py\", \"r\") as f:\n",
    "    mini = f.read()\n",
    "  txt += f\"{txt6}{'=' * len(txt6)}\\n{mini}\\n\\n\\n\"\n",
    "\n",
    "with open(\"details.txt\", \"w\") as f:\n",
    "  f.write(txt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 15,
     "status": "aborted",
     "timestamp": 1656230067381,
     "user": {
      "displayName": "joshana shakya",
      "userId": "03824919138905749941"
     },
     "user_tz": -345
    },
    "id": "p8jVlXEqVAR4"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CodeBERT_SingleTrans_sourcecode_nmt.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
